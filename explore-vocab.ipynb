{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cbcc69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98f77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '|': 4, 'া': 5, 'র': 6, 'ে': 7, '্': 8, 'ি': 9, 'ন': 10, 'ক': 11, 'য': 12, 'ব': 13, 'ত': 14, 'স': 15, 'ল': 16, 'প': 17, '়': 18, 'ম': 19, 'ট': 20, 'ু': 21, 'দ': 22, 'এ': 23, 'হ': 24, 'ো': 25, 'জ': 26, 'গ': 27, 'শ': 28, 'ছ': 29, 'ী': 30, 'ই': 31, 'থ': 32, 'ভ': 33, 'অ': 34, 'আ': 35, 'ং': 36, 'ষ': 37, 'চ': 38, 'ড': 39, 'ধ': 40, 'ও': 41, 'ণ': 42, 'খ': 43, 'উ': 44, 'ফ': 45, '\"': 46, 'ূ': 47, '0': 48, 'ৃ': 49, '।': 50, 'ঘ': 51, '1': 52, 'ঠ': 53, 'ঁ': 54, '-': 55, 'ঞ': 56, '2': 57, 'ৈ': 58, 'ঙ': 59, 'ৌ': 60, '9': 61, '5': 62, '4': 63, 'ৎ': 64, '3': 65, 'ঝ': 66, '০': 67, '6': 68, '8': 69, ',': 70, \"'\": 71, '7': 72, 'a': 73, '১': 74, '.': 75, 'ঃ': 76, 'c': 77, '৪': 78, ':': 79, '২': 80, '৯': 81, 'ঐ': 82, 't': 83, 's': 84, '/': 85, 'm': 86, 'p': 87, '৬': 88, 'i': 89, '৫': 90, '৮': 91, 'n': 92, '৩': 93, 'ঢ': 94, '৭': 95, 'u': 96, 'o': 97, 'r': 98, 'd': 99, 'h': 100, 'e': 101, 'v': 102, 'l': 103, 'g': 104, 'b': 105, 'w': 106, 'ঈ': 107, ';': 108, 'y': 109, 'k': 110, 'x': 111, '\\u200d': 112, '%': 113, 'f': 114, '!': 115, 'ঔ': 116, '¥': 117, 'õ': 118, 'ঊ': 119, 'ঋ': 120, '°': 121, 'q': 122, 'í': 123, '+': 124, 'ü': 125, 'z': 126, '[': 127, ']': 128, '£': 129, '৷': 130, '?': 131, 'j': 132, 'ú': 133, 'á': 134, '—': 135}\n"
     ]
    }
   ],
   "source": [
    "# Your list of vocabulary\n",
    "vocab_list = ['<pad>',\n",
    " '<s>',\n",
    " '</s>',\n",
    " '<unk>',\n",
    " '|',\n",
    " 'া',\n",
    " 'র',\n",
    " 'ে',\n",
    " '্',\n",
    " 'ি',\n",
    " 'ন',\n",
    " 'ক',\n",
    " 'য',\n",
    " 'ব',\n",
    " 'ত',\n",
    " 'স',\n",
    " 'ল',\n",
    " 'প',\n",
    " '়',\n",
    " 'ম',\n",
    " 'ট',\n",
    " 'ু',\n",
    " 'দ',\n",
    " 'এ',\n",
    " 'হ',\n",
    " 'ো',\n",
    " 'জ',\n",
    " 'গ',\n",
    " 'শ',\n",
    " 'ছ',\n",
    " 'ী',\n",
    " 'ই',\n",
    " 'থ',\n",
    " 'ভ',\n",
    " 'অ',\n",
    " 'আ',\n",
    " 'ং',\n",
    " 'ষ',\n",
    " 'চ',\n",
    " 'ড',\n",
    " 'ধ',\n",
    " 'ও',\n",
    " 'ণ',\n",
    " 'খ',\n",
    " 'উ',\n",
    " 'ফ',\n",
    " '\"',\n",
    " 'ূ',\n",
    " '0',\n",
    " 'ৃ',\n",
    " '।',\n",
    " 'ঘ',\n",
    " '1',\n",
    " 'ঠ',\n",
    " 'ঁ',\n",
    " '-',\n",
    " 'ঞ',\n",
    " '2',\n",
    " 'ৈ',\n",
    " 'ঙ',\n",
    " 'ৌ',\n",
    " '9',\n",
    " '5',\n",
    " '4',\n",
    " 'ৎ',\n",
    " '3',\n",
    " 'ঝ',\n",
    " '০',\n",
    " '6',\n",
    " '8',\n",
    " ',',\n",
    " \"'\",\n",
    " '7',\n",
    " 'a',\n",
    " '১',\n",
    " '.',\n",
    " 'ঃ',\n",
    " 'c',\n",
    " '৪',\n",
    " ':',\n",
    " '২',\n",
    " '৯',\n",
    " 'ঐ',\n",
    " 't',\n",
    " 's',\n",
    " '/',\n",
    " 'm',\n",
    " 'p',\n",
    " '৬',\n",
    " 'i',\n",
    " '৫',\n",
    " '৮',\n",
    " 'n',\n",
    " '৩',\n",
    " 'ঢ',\n",
    " '৭',\n",
    " 'u',\n",
    " 'o',\n",
    " 'r',\n",
    " 'd',\n",
    " 'h',\n",
    " 'e',\n",
    " 'v',\n",
    " 'l',\n",
    " 'g',\n",
    " 'b',\n",
    " 'w',\n",
    " 'ঈ',\n",
    " ';',\n",
    " 'y',\n",
    " 'k',\n",
    " 'x',\n",
    " '\\u200d',\n",
    " '%',\n",
    " 'f',\n",
    " '!',\n",
    " 'ঔ',\n",
    " '¥',\n",
    " 'õ',\n",
    " 'ঊ',\n",
    " 'ঋ',\n",
    " '°',\n",
    " 'q',\n",
    " 'í',\n",
    " '+',\n",
    " 'ü',\n",
    " 'z',\n",
    " '[',\n",
    " ']',\n",
    " '£',\n",
    " '৷',\n",
    " '?',\n",
    " 'j',\n",
    " 'ú',\n",
    " 'á',\n",
    " '—']\n",
    "\n",
    "# Create a dictionary from the vocabulary list with unique keys\n",
    "vocab_dict = {word: index for index, word in enumerate(vocab_list)}\n",
    "\n",
    "# Print the vocabulary dictionary\n",
    "print(vocab_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f938748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c257a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['”',\n",
       " '।',\n",
       " 'ৰ',\n",
       " 'ৈ',\n",
       " 'ঘ',\n",
       " 'হ',\n",
       " 'স',\n",
       " 'শ',\n",
       " 'ঃ',\n",
       " 'ছ',\n",
       " 'আ',\n",
       " 'ঈ',\n",
       " '়',\n",
       " 'ও',\n",
       " 'ট',\n",
       " '–',\n",
       " 'উ',\n",
       " 'প',\n",
       " 'চ',\n",
       " 'ঝ',\n",
       " '—',\n",
       " 'ঋ',\n",
       " 'ভ',\n",
       " 'ে',\n",
       " 'ঢ',\n",
       " 'ন',\n",
       " 'ঠ',\n",
       " 'ু',\n",
       " '“',\n",
       " 'য়',\n",
       " 'ল',\n",
       " 'ঢ়',\n",
       " '…',\n",
       " 'ি',\n",
       " '্',\n",
       " 'ণ',\n",
       " 'ড়',\n",
       " 'এ',\n",
       " 'ী',\n",
       " '৷',\n",
       " '॥',\n",
       " 'থ',\n",
       " '|',\n",
       " '/',\n",
       " '‘',\n",
       " 'ো',\n",
       " 'ত',\n",
       " 'ঐ',\n",
       " 'ষ',\n",
       " 'দ',\n",
       " 'ধ',\n",
       " 'খ',\n",
       " 'ঙ',\n",
       " 'ৌ',\n",
       " 'র',\n",
       " 'ূ',\n",
       " \"'\",\n",
       " '’',\n",
       " 'ং',\n",
       " 'ৎ',\n",
       " 'া',\n",
       " 'ৃ',\n",
       " 'ব',\n",
       " 'য',\n",
       " 'ঊ',\n",
       " 'ঁ',\n",
       " 'ই',\n",
       " 'ৗ',\n",
       " 'ঔ',\n",
       " 'ক',\n",
       " 'ম',\n",
       " '‚',\n",
       " 'ড',\n",
       " 'ঞ',\n",
       " 'অ',\n",
       " 'ফ',\n",
       " 'জ',\n",
       " 'গ',\n",
       " '৵',\n",
       " '[UNK]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/ubuntu/bengali/speech-to-text/vocab.json') as fopen:\n",
    "    vocab = json.load(fopen)\n",
    "    vocab = {v: k for k, v in vocab.items()}\n",
    "    \n",
    "vocab = [vocab[i] for i in range(len(vocab))]\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13355262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f5bb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vocab(texts):\n",
    "    \"\"\"\n",
    "    Get unique characters from all the text in a list\n",
    "    \"\"\"\n",
    "    all_text = \" \".join(texts)\n",
    "    vocab = list(set(all_text))\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def save_vocab(dataframe):\n",
    "    \"\"\"\n",
    "    Saves the processed vocab file as 'vocab.json', to be ingested by tokenizer\n",
    "    \"\"\"\n",
    "    vocab = construct_vocab(dataframe['sentence'].tolist())\n",
    "    vocab_dict = {v: k for k, v in enumerate(vocab)}\n",
    "    vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "    _ = vocab_dict.pop(\" \")\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "    vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "    \n",
    "    return vocab_dict\n",
    "\n",
    "def remove_special_characters(string):\n",
    "\n",
    "    chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "    \n",
    "    clean = re.sub(chars_to_ignore_regex, \"\", string).lower() + \" \"\n",
    "  \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeaf14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/bengali/data/train.csv')\n",
    "\n",
    "df['sentence'] = df['sentence'].apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b39b262d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = save_vocab(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb5df926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('vocab.json', 'w') as fopen:\n",
    "    json.dump(train_vocab, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a10d6537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['”',\n",
       " '।',\n",
       " 'ৰ',\n",
       " 'ৈ',\n",
       " 'ঘ',\n",
       " 'হ',\n",
       " 'স',\n",
       " 'শ',\n",
       " 'ঃ',\n",
       " 'ছ',\n",
       " 'আ',\n",
       " 'ঈ',\n",
       " '়',\n",
       " 'ও',\n",
       " 'ট',\n",
       " '–',\n",
       " 'উ',\n",
       " 'প',\n",
       " 'চ',\n",
       " 'ঝ',\n",
       " '—',\n",
       " 'ঋ',\n",
       " 'ভ',\n",
       " 'ে',\n",
       " 'ঢ',\n",
       " 'ন',\n",
       " 'ঠ',\n",
       " 'ু',\n",
       " '“',\n",
       " 'য়',\n",
       " 'ল',\n",
       " 'ঢ়',\n",
       " '…',\n",
       " 'ি',\n",
       " '্',\n",
       " 'ণ',\n",
       " 'ড়',\n",
       " 'এ',\n",
       " 'ী',\n",
       " '৷',\n",
       " '॥',\n",
       " 'থ',\n",
       " '|',\n",
       " '/',\n",
       " '‘',\n",
       " 'ো',\n",
       " 'ত',\n",
       " 'ঐ',\n",
       " 'ষ',\n",
       " 'দ',\n",
       " 'ধ',\n",
       " 'খ',\n",
       " 'ঙ',\n",
       " 'ৌ',\n",
       " 'র',\n",
       " 'ূ',\n",
       " \"'\",\n",
       " '’',\n",
       " 'ং',\n",
       " 'ৎ',\n",
       " 'া',\n",
       " 'ৃ',\n",
       " 'ব',\n",
       " 'য',\n",
       " 'ঊ',\n",
       " 'ঁ',\n",
       " 'ই',\n",
       " 'ৗ',\n",
       " 'ঔ',\n",
       " 'ক',\n",
       " 'ম',\n",
       " '‚',\n",
       " 'ড',\n",
       " 'ঞ',\n",
       " 'অ',\n",
       " 'ফ',\n",
       " 'জ',\n",
       " 'গ',\n",
       " '৵',\n",
       " '[UNK]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('vocab.json') as fopen:\n",
    "    vocab = json.load(fopen)\n",
    "    vocab = {v: k for k, v in vocab.items()}\n",
    "    \n",
    "vocab = [vocab[i] for i in range(len(vocab))]\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31f0ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor\n",
    ") \n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "        \"vocab.json\", \n",
    "        unk_token=\"[UNK]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        word_delimiter_token=\"|\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71700997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ও বলেছে আপনার ঠিকানা '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51908824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ও বলেছে আপনার ঠিকানা'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(df['sentence'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc6e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
