{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70346fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 05:26:18.598368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 05:26:19.482141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Cannot import beam_search_ops from Tensorflow Addons, ['malaya.jawi_rumi.deep_model', 'malaya.phoneme.deep_model', 'malaya.rumi_jawi.deep_model', 'malaya.stem.deep_model'] will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "check compatible Tensorflow version with Tensorflow Addons at https://github.com/tensorflow/addons/releases\n",
      "`openai-whisper` is not available, native whisper processor is not available, will use huggingface processor instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-28 05:26:29,094] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import torch\n",
    "from malaya_speech.utils import torch_featurization\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca06cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/ubuntu/bengali/data/LATEST_DATA_WAV2VEC2_DURATION.parquet\n",
    "# 1. load the dataset\n",
    "df = pd.read_parquet(\"/home/ubuntu/bengali/data/LATEST_DATA_WAV2VEC2_DURATION.parquet\")\n",
    "train, val = train_test_split(df, test_size=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896bd640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f12dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    SR = 16000\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.audio = Audio(sampling_rate=self.SR)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.loc[idx]['path']\n",
    "        y = self.df.loc[idx]['sentence']\n",
    "\n",
    "        r = self.audio.decode_example(self.audio.encode_example(x))\n",
    "        return r['array']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceab46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BengaliDataset(val.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a834f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor(train_dataset[0]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee419b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34582f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "torchaudio.__version__\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_statistics(samples):\n",
    "    E_x = 0\n",
    "    E_x_2 = 0\n",
    "    N = 0\n",
    "\n",
    "    for sample in tqdm(samples):\n",
    "#         print(sample[0].squeeze().dtype)\n",
    "        mel_spec = torch_featurization.melspectrogram(sample[0].squeeze())\n",
    "        scaled_mel_spec = torch_featurization.piecewise_linear_log(mel_spec)\n",
    "        sum = scaled_mel_spec.sum(0)\n",
    "        sq_sum = scaled_mel_spec.pow(2).sum(0)\n",
    "        M = scaled_mel_spec.size(0)\n",
    "\n",
    "        E_x = E_x * (N / (N + M)) + sum / (N + M)\n",
    "        E_x_2 = E_x_2 * (N / (N + M)) + sq_sum / (N + M)\n",
    "        N += M\n",
    "\n",
    "    return E_x, (E_x_2 - E_x**2) ** 0.5\n",
    "\n",
    "mean, stddev = generate_statistics(iter(dataloader))\n",
    "\n",
    "json_str = json.dumps({\"mean\": mean.tolist(), \"invstddev\": (1 / stddev).tolist()}, indent=2)\n",
    "with open('malay-stats.json', \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d20ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, stddev = generate_statistics(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc11bdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps({\"mean\": mean.tolist(), \"invstddev\": (1 / stddev).tolist()}, indent=2)\n",
    "with open('malay-stats.json', \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ba4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccd23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
