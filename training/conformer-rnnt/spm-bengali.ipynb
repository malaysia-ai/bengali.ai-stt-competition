{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4dc5ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>path</th>\n",
       "      <th>filename_x</th>\n",
       "      <th>durs</th>\n",
       "      <th>filename_y</th>\n",
       "      <th>length_sentence</th>\n",
       "      <th>check_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>এক মাইলের কম থেকে শুরু করে বেশি দূরত্ব যা কিনা...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10007728875760...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10007728875760...</td>\n",
       "      <td>10.20</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10007728875760...</td>\n",
       "      <td>20</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ব্রাজিলের জাতীয় কংগ্রেস সামাজিক বিবাহকে 10 বছর...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10027935128938...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10027935128938...</td>\n",
       "      <td>14.04</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10027935128938...</td>\n",
       "      <td>24</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>স্থলরেখা থেকে অনেক দূরে থাকায় মার্কিন যুক্তরাষ...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10031075386419...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10031075386419...</td>\n",
       "      <td>14.04</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10031075386419...</td>\n",
       "      <td>18</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>বর্তমানে অনেক সামি আধুনিক ব্যবসায় কাজ করে।সামি...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10032118353482...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10032118353482...</td>\n",
       "      <td>9.36</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10032118353482...</td>\n",
       "      <td>14</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>অশ্বরোহীর পাদান তার পায়ের সাপোর্টের জন্য যা অশ...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10033964478741...</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10033964478741...</td>\n",
       "      <td>8.52</td>\n",
       "      <td>/home/ubuntu/bengali/data/train/10033964478741...</td>\n",
       "      <td>12</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  এক মাইলের কম থেকে শুরু করে বেশি দূরত্ব যা কিনা...   \n",
       "1  ব্রাজিলের জাতীয় কংগ্রেস সামাজিক বিবাহকে 10 বছর...   \n",
       "2  স্থলরেখা থেকে অনেক দূরে থাকায় মার্কিন যুক্তরাষ...   \n",
       "3  বর্তমানে অনেক সামি আধুনিক ব্যবসায় কাজ করে।সামি...   \n",
       "4  অশ্বরোহীর পাদান তার পায়ের সাপোর্টের জন্য যা অশ...   \n",
       "\n",
       "                                                path  \\\n",
       "0  /home/ubuntu/bengali/data/train/10007728875760...   \n",
       "1  /home/ubuntu/bengali/data/train/10027935128938...   \n",
       "2  /home/ubuntu/bengali/data/train/10031075386419...   \n",
       "3  /home/ubuntu/bengali/data/train/10032118353482...   \n",
       "4  /home/ubuntu/bengali/data/train/10033964478741...   \n",
       "\n",
       "                                          filename_x   durs  \\\n",
       "0  /home/ubuntu/bengali/data/train/10007728875760...  10.20   \n",
       "1  /home/ubuntu/bengali/data/train/10027935128938...  14.04   \n",
       "2  /home/ubuntu/bengali/data/train/10031075386419...  14.04   \n",
       "3  /home/ubuntu/bengali/data/train/10032118353482...   9.36   \n",
       "4  /home/ubuntu/bengali/data/train/10033964478741...   8.52   \n",
       "\n",
       "                                          filename_y  length_sentence  \\\n",
       "0  /home/ubuntu/bengali/data/train/10007728875760...               20   \n",
       "1  /home/ubuntu/bengali/data/train/10027935128938...               24   \n",
       "2  /home/ubuntu/bengali/data/train/10031075386419...               18   \n",
       "3  /home/ubuntu/bengali/data/train/10032118353482...               14   \n",
       "4  /home/ubuntu/bengali/data/train/10033964478741...               12   \n",
       "\n",
       "  check_len  \n",
       "0     valid  \n",
       "1     valid  \n",
       "2     valid  \n",
       "3     valid  \n",
       "4     valid  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('../data/LATEST_DATA_WAV2VEC2_DURATION.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc88058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spm-text.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(df['sentence'].tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2f1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f70221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: spm-text.txt\n",
      "  input_format: \n",
      "  model_prefix: spm-bengali\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1023\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 18446744073709551615\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 0\n",
      "  eos_id: 2\n",
      "  pad_id: 1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: spm-text.txt\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 967964 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=52918846\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 100% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=136\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 967964 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=33985339\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 348772 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 967964\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 196528\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 196528 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=119956 obj=11.9811 num_tokens=364980 num_tokens/piece=3.04262\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=91652 obj=9.738 num_tokens=364322 num_tokens/piece=3.97506\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=68708 obj=9.69356 num_tokens=380399 num_tokens/piece=5.53646\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=68662 obj=9.68014 num_tokens=380596 num_tokens/piece=5.54304\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=51492 obj=9.73653 num_tokens=408527 num_tokens/piece=7.9338\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=51492 obj=9.72227 num_tokens=408524 num_tokens/piece=7.93374\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=38619 obj=9.814 num_tokens=441102 num_tokens/piece=11.4219\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=38619 obj=9.79412 num_tokens=441122 num_tokens/piece=11.4224\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=28963 obj=9.92726 num_tokens=475947 num_tokens/piece=16.4329\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=28963 obj=9.90028 num_tokens=475953 num_tokens/piece=16.4331\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=21722 obj=10.0804 num_tokens=511782 num_tokens/piece=23.5605\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=21722 obj=10.0442 num_tokens=511776 num_tokens/piece=23.5603\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=16291 obj=10.2738 num_tokens=549335 num_tokens/piece=33.7202\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=16291 obj=10.2278 num_tokens=549342 num_tokens/piece=33.7206\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12218 obj=10.5053 num_tokens=585568 num_tokens/piece=47.9267\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=12218 obj=10.4499 num_tokens=585593 num_tokens/piece=47.9287\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=9163 obj=10.7824 num_tokens=622900 num_tokens/piece=67.9799\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=9163 obj=10.7154 num_tokens=622935 num_tokens/piece=67.9837\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=6872 obj=11.0963 num_tokens=663364 num_tokens/piece=96.5314\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=6872 obj=11.0177 num_tokens=663442 num_tokens/piece=96.5428\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5154 obj=11.4556 num_tokens=704457 num_tokens/piece=136.682\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5154 obj=11.3682 num_tokens=704507 num_tokens/piece=136.691\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3865 obj=11.8553 num_tokens=744510 num_tokens/piece=192.629\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3865 obj=11.757 num_tokens=744533 num_tokens/piece=192.635\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2898 obj=12.3118 num_tokens=792571 num_tokens/piece=273.489\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2898 obj=12.19 num_tokens=792608 num_tokens/piece=273.502\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2173 obj=12.8096 num_tokens=840675 num_tokens/piece=386.873\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2173 obj=12.6776 num_tokens=840704 num_tokens/piece=386.886\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1629 obj=13.3563 num_tokens=890981 num_tokens/piece=546.95\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1629 obj=13.2081 num_tokens=891154 num_tokens/piece=547.056\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1221 obj=13.9224 num_tokens=945868 num_tokens/piece=774.667\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1221 obj=13.763 num_tokens=945998 num_tokens/piece=774.773\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1125 obj=13.9685 num_tokens=958254 num_tokens/piece=851.781\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1125 obj=13.93 num_tokens=958295 num_tokens/piece=851.818\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: spm-bengali.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: spm-bengali.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "    input='spm-text.txt', model_prefix='spm-bengali',\n",
    "    vocab_size=1023,\n",
    "    model_type=\"unigram\",\n",
    "    input_sentence_size=-1,\n",
    "    character_coverage=1.0,\n",
    "    bos_id=0,\n",
    "    pad_id=1,\n",
    "    eos_id=2,\n",
    "    unk_id=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
