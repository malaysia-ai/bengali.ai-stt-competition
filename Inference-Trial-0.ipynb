{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09883939",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 15:19:55.120393: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-01 15:19:56.824783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-01 15:19:59,425] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import librosa\n",
    "from transformers import AutoProcessor, Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6ad383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.df.loc[idx]['path']\n",
    "        audio_array = self.read_audio(audio_path)\n",
    "\n",
    "        inputs = self.processor(\n",
    "            audio_array,\n",
    "            sampling_rate=16_000,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        with self.processor.as_target_processor():\n",
    "            labels = self.processor(self.df.loc[idx]['sentence']).input_ids\n",
    "\n",
    "        return {'input_values': inputs['input_values'].squeeze(0), 'labels': labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def read_audio(self, mp3_path):\n",
    "        target_sr = 16000  # Set the target sampling rate\n",
    "\n",
    "        audio, sr = librosa.load(mp3_path, sr=None)  # Load with original sampling rate\n",
    "        audio_array = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "        return audio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541aaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"/home/ubuntu/bengali/aisyah/training/mms-1b/checkpoint-16000\")\n",
    "# model = Wav2Vec2ForCTC.from_pretrained(\"/home/ubuntu/bengali/aisyah/training/mms-1b/checkpoint-16000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5940cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.set_target_lang(\"ben\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36cad1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Processor:\n",
       "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
       "  \"feature_size\": 1,\n",
       "  \"padding_side\": \"right\",\n",
       "  \"padding_value\": 0,\n",
       "  \"processor_class\": \"Wav2Vec2Processor\",\n",
       "  \"return_attention_mask\": true,\n",
       "  \"sampling_rate\": 16000\n",
       "}\n",
       "\n",
       "- tokenizer: Wav2Vec2CTCTokenizer(name_or_path='/home/ubuntu/bengali/aisyah/training/mms-1b/checkpoint-16000', vocab_size=136, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffc5c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2CTCTokenizer(name_or_path='/home/ubuntu/bengali/aisyah/training/mms-1b/checkpoint-16000', vocab_size=136, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbcc255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d647f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21e0702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.json', 'w') as fopen:\n",
    "    json.dump(processor.tokenizer.vocab['ben'], fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e1088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"vocab.json\",\n",
    "    unk_token=\"<unk>\",\n",
    "    pad_token=\"<pad>\",\n",
    "    word_delimiter_token=\"|\"\n",
    ")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa7fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/train.csv')\n",
    "test = test[test['split'] =='valid'].reset_index(drop=True)\n",
    "test['path'] = test['id'].apply(lambda x: os.path.join('/home/ubuntu/bengali/data/train_mp3s', x+'.mp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef8fc5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "test_ds = BengaliDataset(test, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6041150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    input_values = [item['input_values'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    input_values_padded = pad_sequence(input_values, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    labels = [torch.tensor(label) for label in labels]\n",
    "\n",
    "    return {'input_values': input_values_padded, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa447af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=custom_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a211145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1280, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1280, 1280, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-47): 48 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "            (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (adapter_layer): Wav2Vec2AttnAdapterLayer(\n",
       "            (norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (linear_1): Linear(in_features=1280, out_features=16, bias=True)\n",
       "            (act_fn): ReLU()\n",
       "            (linear_2): Linear(in_features=16, out_features=1280, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.05, inplace=False)\n",
       "  (lm_head): Linear(in_features=1280, out_features=136, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7653985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2959 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|██████████| 2959/2959 [13:17<00:00,  3.71it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x = batch[\"input_values\"]\n",
    "        x = x.to(\"cuda\", non_blocking=True)\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits\n",
    "        predicted_ids = torch.argmax(y, dim=-1)\n",
    "        \n",
    "        batch_size = predicted_ids.shape[0]\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            transcription = processor.decode(predicted_ids[i])\n",
    "            sentences.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0b96897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26888149151446894\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "jiwerresult_0 = []\n",
    "\n",
    "for x in range(len(sentences)):\n",
    "\n",
    "    jiwer_ = jiwer.wer(sentences[x],test.iloc[x,1])\n",
    "\n",
    "    jiwerresult_0.append(jiwer_)\n",
    "    \n",
    "    \n",
    "avg_wer_0 = sum(jiwerresult_0)/len(sentences)\n",
    "print(avg_wer_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32f6b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bnunicodenormalizer import Normalizer\n",
    "\n",
    "bnorm = Normalizer()\n",
    "\n",
    "def postprocess(sentence):\n",
    "    period_set = set([\".\", \"?\", \"!\", \"।\"])\n",
    "    _words = [bnorm(word)['normalized']  for word in sentence.split()]\n",
    "    sentence = \" \".join([word for word in _words if word is not None])\n",
    "    try:\n",
    "        if sentence[-1] not in period_set:\n",
    "            sentence+=\"।\"\n",
    "    except:\n",
    "        # print(sentence)\n",
    "        sentence = \"।\"\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bc03dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    data = postprocess(sentence)\n",
    "    cleaned_sentences.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fde8330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3337583934118714\n"
     ]
    }
   ],
   "source": [
    "jiwerresult_1 = []\n",
    "\n",
    "for x in range(len(cleaned_sentences)):\n",
    "\n",
    "    jiwer_ = jiwer.wer(cleaned_sentences[x],test.iloc[x,1])\n",
    "\n",
    "    jiwerresult_1.append(jiwer_)\n",
    "    \n",
    "    \n",
    "avg_wer_1 = sum(jiwerresult_1)/len(cleaned_sentences)\n",
    "print(avg_wer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "405ed74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_sentences = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    data = sentence.replace(\"<unk>\",\"\")\n",
    "    unk_sentences.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e12d663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26886597708432697\n"
     ]
    }
   ],
   "source": [
    "jiwerresult_2 = []\n",
    "\n",
    "for x in range(len(unk_sentences)):\n",
    "\n",
    "    jiwer_ = jiwer.wer(unk_sentences[x],test.iloc[x,1])\n",
    "\n",
    "    jiwerresult_2.append(jiwer_)\n",
    "    \n",
    "    \n",
    "avg_wer_2 = sum(jiwerresult_2)/len(unk_sentences)\n",
    "print(avg_wer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e786761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0.26888149151446894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "245423c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_1 = 0.26886597708432697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "98b371cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num > num1\n"
     ]
    }
   ],
   "source": [
    "if num > num_1:\n",
    "    print(\"num > num1\")\n",
    "else:\n",
    "    print(\"num < num1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26a41d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('তিনি এবং তার মা তাদের পৈতৃক বাড়িতে থেকে প্রতিবেশীদের দ্বারা অনেক তিরস্কার সহ্য করেন।',\n",
       " 'তিনি এবং তাঁর মা তাদের পৈতৃক বাড়িতে থেকে প্রতিবেশীদের দ্বারা অনেক তিরস্কার সহ্য করেন।')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0], test[\"sentence\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43702066",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: তিনি এবং তার মা তাদের পৈতৃক বাড়িতে থেকে প্রতিবেশীদের দ্বারা অনেক তিরস্কার সহ্য করেন।\n",
      "Test Set: তিনি এবং তাঁর মা তাদের পৈতৃক বাড়িতে থেকে প্রতিবেশীদের দ্বারা অনেক তিরস্কার সহ্য করেন।\n",
      "================================\n",
      "Predicted: কৃত্তিবাস রামায়ন বহির্ভূত অনেক গল্প এই অনুবাদে গ্রহণ করেছিলেন।\n",
      "Test Set: কৃত্তিবাস রামায়ণ-বহির্ভূত অনেক গল্প এই অনুবাদে গ্রহণ করেছিলেন।\n",
      "================================\n",
      "Predicted: তিনি তার সুশৃং্হল সামরিক বাহিনী এবং সুগঠিত শাসন কাঠামোর মাধ্যমে একটি দক্ষ শাসন ব্যবস্থা প্রতিষ্ঠিত করেন।\n",
      "Test Set: তিনি তার সুশৃঙ্খল সামরিক বাহিনী এবং সুগঠিত শাসন কাঠামোর মাধ্যমে একটি দক্ষ শাসন ব্যবস্থা প্রতিষ্ঠিত করেন।\n",
      "================================\n",
      "Predicted: তিনি বিজয়নগজ সাম্রাজ্যের বিরুদ্ধে এবং বিজাপুরের মুসলিম প্রতিবেশীদের বিরুদ্ধেও যুদ্ধ করেছিলেন।\n",
      "Test Set: তিনি বিজয়নগর সাম্রাজ্যের বিরুদ্ধে এবং বিজাপুরের মুসলিম প্রতিবেশীদের বিরুদ্ধেও যুদ্ধ করেছিলেন।\n",
      "================================\n",
      "Predicted: এটি মূলত একটি মরুময় অঞ্চব।\n",
      "Test Set: এটি মূলত একটি মরুময় অঞ্চল।\n",
      "================================\n",
      "Predicted: সড়কটি বিহার পশ্চিমবঙ্গ সীমান্ত অতিক্রম গর়ে পশ্চিমবঙ্গ রাজ্যে প্রবেশ করে উত্তর দিনাজ্পুর জেলা হয়ে।\n",
      "Test Set: সড়কটি বিহার-পশ্চিমবঙ্গ সীমান্ত অতিক্রম করে পশ্চিমবঙ্গ রাজ্যে প্রবেশ করে উত্তর দিনাজপুর জেলা হয়ে।\n",
      "================================\n",
      "Predicted: মাঝেমধ্যে অন্যান্য দেশের দলও এতে অংশ নেই।\n",
      "Test Set: মাঝে-মধ্যে অন্যান্য দেশের দলও এতে অংশ নেয়।\n",
      "================================\n",
      "Predicted: বলকে অবমুক্ত করে পুনরায় শারীরিক ভারসাম্য ফিরিয়ে নিয়ে আনতে হবে।\n",
      "Test Set: বলকে অবমুক্ত করে পুনরায় শারীরিক ভারসাম্য ফিরিয়ে নিয়ে আনতে হবে।\n",
      "================================\n",
      "Predicted: সাংস্কৃতিক উন্নয়নে অত্র প্রতিষ্ঠানটি অত্যন্ত সুপরিচিত।\n",
      "Test Set: সাংস্কৃতিক উন্নয়নে অত্র প্রতিষ্ঠানটি অত্যন্ত সুপরিচিত।\n",
      "================================\n",
      "Predicted: যথারিচি সেখানে ও সফল্যের স্বাক্ষর রাখলেন সিদ্দি।\n",
      "Test Set: যথারীতি সেখানেও সাফল্যের স্বাক্ষর রাখলেন সিদ্দিক।\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(f\"Predicted: {sentences[x]}\")\n",
    "    print(f\"Test Set: {test['sentence'][x]}\")\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbeef135",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 \n",
    "for sentence in sentences:\n",
    "    if \"unk\" in sentence:\n",
    "#         print(sentence)\n",
    "#         print(index)\n",
    "#         break\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "538c6a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d4a7615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'এমনকি নামাযের সময়ও সঙ্গে রাখতেন।'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['sentence'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7222ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a12dfda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29588"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0419bffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59286"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14b1de63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b5e0568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29697"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[29589:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "955094a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29588"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8221c5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences[-10_000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b1d7cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = sentences[-29_588:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22d55952",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_check = test[-29_588:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7ac9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "\n",
    "jiwerresult = []\n",
    "\n",
    "for x in range(len(check)):\n",
    "\n",
    "    jiwer_ = jiwer.wer(check[x],test_check.iloc[x,1])\n",
    "\n",
    "    jiwerresult.append(jiwer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e730412c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2729789306789587"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_wer = sum(jiwerresult)/len(jiwerresult)\n",
    "avg_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4b17ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26888149151446894"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_wer = sum(jiwerresult)/len(jiwerresult)\n",
    "avg_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a92547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec82088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8130819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5918 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py:155: UserWarning: `as_target_processor` is deprecated and will be removed in v5 of Transformers. You can process your labels by using the argument `text` of the regular `__call__` method (either in the same call as your audio inputs, or in a separate call.\n",
      "  warnings.warn(\n",
      "100%|█████████▉| 5917/5918 [13:03<00:00,  7.56it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for dimension 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m predicted_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[0;32m---> 12\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mpredicted_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m     sentences\u001b[38;5;241m.\u001b[39mappend(transcription)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for dimension 0 with size 3"
     ]
    }
   ],
   "source": [
    "# sentences = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_loader):\n",
    "#         x = batch[\"input_values\"]\n",
    "#         x = x.to(\"cuda\", non_blocking=True)\n",
    "#         with torch.cuda.amp.autocast(True):\n",
    "#             y = model(x).logits\n",
    "#         predicted_ids = torch.argmax(y, dim=-1)\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "#             transcription = processor.decode(predicted_ids[i])\n",
    "#             sentences.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fc9cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"একটু বয়েস হলে একটি বিদেশী।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a57b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = \"একটু বয়স হলে একটি বিদেশী।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "425c5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "if temp == temp_1:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b560c6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp == temp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09b9c37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dadada = \"একটু বয়েস হলে একটি বিদেশী।\"\n",
    "sss = \"একটু বয়েস হলে একটি বিদেশী।\"\n",
    "\n",
    "dadada == sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "052b477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64298062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.285714285714285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = calculate_cer(\"একটু বয়স হলে একটি বিদেশী।\", \"একটু বয়েস হলে একটি বিদেশী।\")\n",
    "check*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf80065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5acb8357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = calculate_wer(\"একটু বয়স হলে একটি বিদেশী।\", \"একটু বয়েস হলে একটি বিদেশী।\")\n",
    "check*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdadb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf54377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
